{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Fallstudie für Lidl: Erweiterung des Süßwarensortiments (Eigenmarke)\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "### Datenexploration\n",
        "\n",
        "#### Daten:\n",
        "\n",
        "- 9 Characteristika von bereits existierenden Süßigkeiten. (boolean)\n",
        "- sugarpercent: Der Perzentilwert des Zuckergehalts innerhalb des Datensatzes.\n",
        "- pricepercent: Der Stückpreis-Prozentwert im Vergleich zum Rest der Menge.\n",
        "- winpercent: Der Gesamtsiegprozentsatz basierend auf 269.000 Matchups.\n",
        "\n",
        "#### Ziel:\n",
        "\n",
        "- Analysiere die Auswirkungen der Charakteristika von Süßwaren auf deren Beliebtheit\n",
        "- Gebe eine Empfehlung auf Basis dieser Analyse für die Eigenschaften einer neuen Süßigkeit.\n"
      ],
      "id": "d73c5f15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Figure: Best and worst performing candy\"\n",
        "\n",
        "from data_processing import CandyDataProcessor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "processor = CandyDataProcessor('candy-data.csv')\n",
        "\n",
        "processor.sort_by_win_percent()"
      ],
      "id": "638bfd49",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Probleme mit dieser Analyse\n",
        "- Beliebtheit ist etwas biased, da der Preis in dem Ranking keine Rolle spielt.\n",
        "  - Marketing, Brand reputation, packaging, current and future market trends sind auch nicht berücksichtigt.\n",
        "  - Preis beinhaltet hier auch höheren Wert durch größere Einzelmenge\n",
        "- Ebenso scheint der Zuckergehalt nicht prozentual zu sein, sondern bezieht sich auf absolute Werte.\n",
        "  - Zuckerranking bedeuted hier oft nicht süßer, sondern einfach dass das Produktgewicht höher ist.\n",
        "\n",
        "#### Was macht eine gute Empfehlung aus?\n",
        "- Sollte möglichst belieble Eigenschaften haben\n",
        "- Sollte nicht zu ähnlich zu Produkten bereits auf dem Markt sein --> we need some uniqueness to stand out\n",
        "- Manche Eigenschaften sind nicht (gut) kombinierbar\n",
        "- Manche Eigenschaften sind (nur) in Kombination begehrt\n",
        "  - Interactions müssen hier analysiert werden!\n"
      ],
      "id": "ca659a1d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Do we have any NaN values:')\n",
        "processor.df.isnull().values.any()"
      ],
      "id": "5242f95b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Figure 1: Summary Statistics for OLS:  winpercent ~ pricequartile\"\n",
        "sns.regplot(x='pricepercent', y='winpercent', data=processor.df)\n",
        "X = sm.add_constant(processor.df['pricepercent'])\n",
        "sm.OLS(processor.df.winpercent,X).fit().summary()"
      ],
      "id": "99eda49e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Einfluss der Preis Variable\n",
        "\n",
        "- Es besteht eine klare pos. Korrelation zw. Preis und Beliebtheit.\n",
        "- fruity, hard, pluribus:\n",
        "  - einzigen vars die im Schnitt Süßigkeiten unbeliebler machen\n",
        "  - auch die einzigen vars die Süßigkeiten billiger machen\n",
        "- Billigsegment verliert gegen teurere Bars im direkten Vergleich, aber unklar ob das auch im Supermarkt mit Preisen der Fall ist\n",
        "  - Könnten im Supermarkt besser performen\n",
        "  - Könnten ein Nichenprodukt sein\n",
        "  - Preis ist hier pro Stück, größere Riegel könnten kleine Packungen mit Bonbons mit purer Masse schlagen\n",
        "\n",
        "#### Correlation matrix\n"
      ],
      "id": "51948a24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| fig-cap: \"Best and worst performing candy\"\n",
        "corr = processor.df.iloc[:, 1:].corr() #correlation matrix\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool)) # mask for upper triangle\n",
        "f, ax = plt.subplots(figsize=(8, 8))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True) # Colormap\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "id": "8608cde5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hier sehen wir welche Eigenschaften öfters zusammen (rot) oder exkludierend (blau) befunden werden:\n",
        "\n",
        "- fruity, hard, fruity oft zusammen\n",
        "- rest oft zusammen\n",
        "- fruity, hard, pluribus selten mit rest\n",
        "\n",
        "--> Sehen wir hier zwei Hauptgruppen: Schokolade und fruity/hard candy?\n",
        "\n",
        "#### Clusteranalysis\n",
        "\n",
        "- Können wir Marktsegmente identifizieren?\n"
      ],
      "id": "bde991cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distance Matrix\n",
        "from scipy.spatial.distance import pdist\n",
        "\n",
        "df_YX = processor.get_num_norm_cols()\n",
        "distance_matrix = pdist(df_YX, metric='euclidean')\n",
        "\n",
        "# Hierarchical Clustering\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "linked = linkage(distance_matrix, method='ward')\n",
        "\n",
        "# Plot the dendrogram\n",
        "plt.figure(figsize=(8, 8))\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Sample index')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n",
        "\n",
        "# Determine Clusters\n",
        "num_clusters = 2 # Specify the number of clusters\n",
        "clusters = fcluster(linked, num_clusters, criterion='maxclust')\n",
        "\n",
        "if len(clusters) != df_YX.shape[0]:\n",
        "    raise ValueError(\"Mismatch between number of clusters and rows in 'df_YX'.\")\n",
        "\n",
        "print(f\"Length of clusters: {len(clusters)}\")\n",
        "print(f\"Number of rows in df_YX: {df_YX.shape[0]}\")\n",
        "\n",
        "# Add cluster labels to the original DataFrame\n",
        "df_YX['Cluster'] = clusters\n",
        "\n",
        "# Visualize clusters\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.scatterplot(x=df_YX['pricepercent'], y=df_YX['winpercent'], hue=df_YX['Cluster'], palette='viridis')\n",
        "plt.title('Clusters in Feature Space')\n",
        "plt.xlabel('Price percentile')\n",
        "plt.ylabel('Winning Percentage')\n",
        "plt.legend(title='Cluster')\n",
        "plt.show()\n",
        "\n",
        "cluster_means = df_YX.groupby('Cluster').mean()\n",
        "print(cluster_means)"
      ],
      "id": "d75c24a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clearly we have two different segments\n",
        "\n",
        "Should we handle them differently?\n",
        "\n",
        "- Compare how different they are\n",
        "  - Visualize data on the first two principal components w.r.t. their attributes\n"
      ],
      "id": "7b4b93cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px\n",
        "\n",
        "# Select and copy relevant columns from the original DataFrame\n",
        "df_attr = processor.get_num_norm_columns()\n",
        "pred_cols = processor.get_predictor_cols()\n",
        "df_attr = df_attr[pred_cols]\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(df_attr)\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(df_attr)\n",
        "\n",
        "# Add PCA and t-SNE results to the DataFrame\n",
        "df_attr['pca-2d-one'] = X_pca[:, 0]\n",
        "df_attr['pca-2d-two'] = X_pca[:, 1]\n",
        "df_attr['tsne-2d-one'] = tsne_results[:, 0]\n",
        "df_attr['tsne-2d-two'] = tsne_results[:, 1]\n",
        "\n",
        "# Plot t-SNE results for selected columns\n",
        "# selected_columns_tsne = ['fruity', 'peanutyalmondy', 'crispedricewafer', 'hard', 'pluribus']\n",
        "# for column in selected_columns_tsne:\n",
        "#      fig_tsne = px.scatter(df_attr, x='tsne-2d-one', y='tsne-2d-two', \n",
        "#                           color=df_attr[column].astype(str),\n",
        "#                           title=f't-SNE colored by {column}',\n",
        "#                           labels={column: column})\n",
        "#     fig_tsne.show()\n",
        "\n",
        "color_map = { '0': 'blue', '1': 'red' }\n",
        "# Plot PCA results for all feature columns\n",
        "selected_columns_pca = ['fruity','hard','nougat','crispedricewafer','peanutyalmondy', 'chocolate','bar','pluribus']\n",
        "for column in selected_columns_pca:\n",
        "    fig_pca = px.scatter(df_attr, x='pca-2d-one', y='pca-2d-two', \n",
        "                        color=df_attr[column].astype(str),\n",
        "                        title=f'PCA colored by {column}',\n",
        "                        color_discrete_map=color_map,\n",
        "                        labels={column: column})\n",
        "    fig_pca.show()"
      ],
      "id": "29c3110c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### How many ingredient based attributes do the sweets have? (i.e. we exclude pluribus, bar, and hard)\n"
      ],
      "id": "40402400"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_attr = df_YX\n",
        "sums = df_attr.sum(axis=1)\n",
        "sum_counts = sums.value_counts().sort_index()\n",
        "sum_counts_df = pd.DataFrame({\n",
        "    'Sum': sum_counts.index,\n",
        "    'Count': sum_counts.values\n",
        "})\n",
        "fig = px.bar(sum_counts_df, x='Sum', y='Count',\n",
        "             title='Sum of Each Feature Column',\n",
        "             labels={'Feature': 'Feature', 'Sum': 'Sum'},\n",
        "             color='Sum',\n",
        "             color_continuous_scale=px.colors.sequential.Plasma)\n",
        "fig.show()"
      ],
      "id": "4369e6c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.DataFrame({\n",
        "    'Number of Attributes': sums,  # Replace `sums` with your independent variable\n",
        "    'Popularity': df['winpercent'] # Replace `y` with your dependent variable (popularity score)\n",
        "})\n",
        "\n",
        "# Calculate the mean popularity for each number of attributes\n",
        "mean_popularity = data.groupby('Number of Attributes')['Popularity'].mean().reset_index()\n",
        "\n",
        "# Create the scatter plot with a Gaussian kernel regression line\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lmplot(x='Number of Attributes', y='Popularity', data=data, \n",
        "           scatter_kws={'s': 50},  # size of scatter points\n",
        "           line_kws={'color': 'red'},  # color of the regression line\n",
        "           lowess=True,  # Gaussian kernel smoothing (locally weighted regression)\n",
        "           )\n",
        "\n",
        "# Plot mean popularity points\n",
        "plt.scatter(mean_popularity['Number of Attributes'], mean_popularity['Popularity'],\n",
        "            color='blue', label='Mean Popularity', zorder=5)\n",
        "\n",
        "# Annotate mean popularity points\n",
        "for i in range(len(mean_popularity)):\n",
        "    plt.annotate(f\"{mean_popularity['Popularity'].iloc[i]:.2f}\",\n",
        "                 (mean_popularity['Number of Attributes'].iloc[i], \n",
        "                  mean_popularity['Popularity'].iloc[i]),\n",
        "                 textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Popularity vs. Number of Attributes with Gaussian Kernel Regression')\n",
        "plt.xlabel('Number of Attributes')\n",
        "plt.ylabel('Popularity')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "e6eee0e7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/markus/miniconda3/envs/lidlcandy/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}